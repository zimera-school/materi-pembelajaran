# Memulai Apache Hive

##  Persyaratan Sistem

Apache Hadoop dan Apache Hive berjalan pada *commodity hardware* atau perangkat keras yang tidak spesifik khusus untuk server, dengan kata lain, perangkat keras yang biasa digunakan oleh pemakai biasa bisa digunakan untuk *stand alone* maupun *clustering*.

Apache Hive dan Apache Hadoop dibuat dengan menggunakan bahasa pemrograman Java sehingga JVM (Java Virtual Machine) diperlukan untuk mengoperasikan Apache Hive dan Apache Hadoop. Informasi tentang kebutuhan JVM untuk masing-masing bisa diperoleh di:

1.  [JVM untuk Apache Hadoop](https://cwiki.apache.org/confluence/display/HADOOP/Hadoop+Java+Versions).
2.  [JVM untuk Apache Hive](https://cwiki.apache.org/confluence/display/Hive/AdminManual+Installation).

Perlu diketahui, dokumentasi untuk Apache Hive bukan merupakan dokumentasi terkini, sehingga untuk keperluan JVM sebaiknya menggunakan persyaratan dari Apache Hadoop:

1.  JDK 8 untuk Apache Hadoop 3.0.x - 3.2.x (mengkompilasi dan menjalankan)
2.  JDK 8 untuk mengkompilasi dan menjalankan Apache Hadoop 3.3.x, dan JRE 11 (*runtime* saja, tidak bisa untuk mengkompilasi kode sumber Apache Hadoop) untuk menjalankan Apache Hadoop 3.3.x
3.  Apache Hadoop yang digunakan adalah versi stabil (3.2.x)

JDK yang bisa digunakan adalah JDK dari [OpenJDK](https://adoptium.net/) maupun dari [Oracle](https://www.oracle.com/java/technologies/downloads/#java8). Versi dari vendor lain seharusnya bisa berjalan juga (misal, Amazon Corretto). 

##  Instalasi dan Konfigurasi Software Prasyarat

### JDK

Petunjuk instalasi untuk JDK:

1.  [Oracle JDK 8](https://docs.oracle.com/javase/8/docs/technotes/guides/install/install_overview.html).
2.  [Adoptium](https://adoptium.net/installation).

### Apache Hadoop

HDFS akan dibuat pada direktori /tmp/hadoop-${user.name}. Semua direktori dan file untuk data maupun metadata akan berada pada direktori tersebut. Jika akan mengubah, gunakan opsi **hadoop.tmp.dir** pada file ``core-default.xml``. Informasi lengkap bisa dilihat di https://hadoop.apache.org/docs/r3.2.3/hadoop-project-dist/hadoop-common/core-default.xml

Direktori lain (untuk metadata serta data) menyesuaikan pada konfigurasi di atas. Jika ingin mengubah, konfigurasi bisa diatur di ``hdfs-default.xml``. Informasi lengkap bisa dilihat pada https://hadoop.apache.org/docs/r3.2.3/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml. Untuk mengubah konfigurasi, atur:

1.  dfs.namenode.name.dir
2.  dfs.datanode.data.dir

##  Instalasi Apache Hive


##  Struktur Direktori Apache Hive


##  Konfigurasi Apache Hive


##  Menjalankan Server Apache Hive: HiveServer2, HCatalog, WebHCatalog


##  Klien untuk Apache Hive


##  Model Data Apache Hive


##  SQL di Apache Hive: DDL, DML, DQL


## Kasus Sederhana

